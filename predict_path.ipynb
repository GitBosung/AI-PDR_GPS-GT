{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'joblib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 115\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m테스트 파일을 찾을 수 없습니다: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 115\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \n",
      "Cell \u001b[1;32mIn[1], line 24\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m trainer \u001b[38;5;241m=\u001b[39m ModelTrainer(window_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, num_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# 스케일러 로드\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m scalers \u001b[38;5;241m=\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[38;5;241m.\u001b[39mload(scaler_path)\n\u001b[0;32m     25\u001b[0m trainer\u001b[38;5;241m.\u001b[39mscaler_acc \u001b[38;5;241m=\u001b[39m scalers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler_acc\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     26\u001b[0m trainer\u001b[38;5;241m.\u001b[39mscaler_gyro \u001b[38;5;241m=\u001b[39m scalers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler_gyro\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'joblib' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from src.data_processor import DataProcessor\n",
    "from src.model_trainer import ModelTrainer\n",
    "from src.trajectory_predictor import TrajectoryPredictor\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib \n",
    "\n",
    "def main():\n",
    "    # 현재 파일의 디렉토리를 기준으로 프로젝트 루트 경로 설정\n",
    "    BASE_DIR = os.getcwd()\n",
    "    \n",
    "    # 저장된 모델과 스케일러 경로 설정\n",
    "    model_path = os.path.join(BASE_DIR, 'saved_models', 'model_20250406_182426.h5')\n",
    "    scaler_path = os.path.join(BASE_DIR, 'saved_models', 'scalers_20250406_182426.joblib')\n",
    "    \n",
    "    if not os.path.exists(model_path) or not os.path.exists(scaler_path):\n",
    "        print(\"학습된 모델이나 스케일러를 찾을 수 없습니다. 먼저 모델을 학습해주세요.\")\n",
    "        return\n",
    "    \n",
    "    # ModelTrainer 인스턴스 생성\n",
    "    trainer = ModelTrainer(window_size=50, num_features=9)\n",
    "    \n",
    "    # 스케일러 로드\n",
    "    scalers = joblib.load(scaler_path)\n",
    "    trainer.scaler_acc = scalers['scaler_acc']\n",
    "    trainer.scaler_gyro = scalers['scaler_gyro']\n",
    "    trainer.scaler_ori = scalers['scaler_ori']\n",
    "    \n",
    "    # 모델 로드\n",
    "    trainer.model = trainer.load_model(model_path)\n",
    "    \n",
    "    # TrajectoryPredictor 인스턴스 생성 (스케일러 전달)\n",
    "    predictor = TrajectoryPredictor(\n",
    "        trainer.model, \n",
    "        trainer.scaler_acc, \n",
    "        trainer.scaler_gyro, \n",
    "        trainer.scaler_ori\n",
    "    )\n",
    "    \n",
    "    # 학습 데이터 경로\n",
    "    learn_data_paths = [\n",
    "        os.path.join(BASE_DIR, 'data', 'learn_data', 'Basket_1.csv'),\n",
    "        os.path.join(BASE_DIR, 'data', 'learn_data', 'Basket_2.csv'),\n",
    "        # os.path.join(BASE_DIR, 'data', 'learn_data', 'Soccer_looking1.csv'),\n",
    "        # os.path.join(BASE_DIR, 'data', 'learn_data', 'Soccer_looking3.csv'),\n",
    "        # os.path.join(BASE_DIR, 'data', 'learn_data', 'Soccer_looking4.csv'),\n",
    "        # os.path.join(BASE_DIR, 'data', 'learn_data', 'Soccer_swing1.csv'),\n",
    "        # os.path.join(BASE_DIR, 'data', 'learn_data', 'Soccer_swing2.csv'),\n",
    "        # os.path.join(BASE_DIR, 'data', 'learn_data', 'Soccer_swing3.csv'),\n",
    "        # os.path.join(BASE_DIR, 'data', 'learn_data', 'Soccer_swing4.csv'),\n",
    "        # os.path.join(BASE_DIR, 'data', 'learn_data', 'Soccer_looking5m_01.csv'),\n",
    "        # os.path.join(BASE_DIR, 'data', 'learn_data', 'Soccer_looking5m_02.csv'),\n",
    "        # os.path.join(BASE_DIR, 'data', 'learn_data', 'Soccer_looking5m_03.csv'),\n",
    "        # os.path.join(BASE_DIR, 'data', 'learn_data', 'Soccer_swing5m_01.csv'),\n",
    "        # os.path.join(BASE_DIR, 'data', 'learn_data', 'Soccer_swing5m_02.csv'),\n",
    "        # os.path.join(BASE_DIR, 'data', 'learn_data', 'Soccer_swing5m_03.csv')\n",
    "    ]\n",
    "\n",
    "    for learn_data_path in learn_data_paths:\n",
    "        if os.path.exists(learn_data_path):\n",
    "            df_learn = DataProcessor.load_and_preprocess_csv(learn_data_path, skiprows=50)\n",
    "            sensor_columns = ['Accelerometer x', 'Accelerometer y', 'Accelerometer z',\n",
    "                            'Gyroscope x', 'Gyroscope y', 'Gyroscope z',\n",
    "                            'Orientation x', 'Orientation y', 'Orientation z']\n",
    "            sensor_data = df_learn[sensor_columns].values\n",
    "            \n",
    "    # TrajectoryPredictor 인스턴스 생성\n",
    "    predictor = TrajectoryPredictor(trainer.model, trainer.scaler_acc, trainer.scaler_gyro, trainer.scaler_ori)\n",
    "    \n",
    "    # 각 학습 데이터 파일에 대해 다시 예측 수행\n",
    "    for learn_data_path in learn_data_paths:\n",
    "        if os.path.exists(learn_data_path):\n",
    "            print(f\"\\n학습에 사용된 파일 처리 중: {os.path.basename(learn_data_path)}\")\n",
    "            \n",
    "            # 학습에 사용된 데이터 로드 및 전처리\n",
    "            df_learned = DataProcessor.load_and_preprocess_csv(learn_data_path, skiprows=50)\n",
    "            \n",
    "            # 예측 경로 시각화\n",
    "            predictor.compare_trajectories(df_learned)\n",
    "            \n",
    "            # 그래프 표시\n",
    "            plt.show()\n",
    "            \n",
    "        else:\n",
    "            print(f\"파일을 찾을 수 없습니다: {learn_data_path}\")\n",
    "    \n",
    "    # 테스트 데이터 경로\n",
    "    test_paths = [\n",
    "        os.path.join(BASE_DIR, 'data', 'test_data', '3f_1.csv'),\n",
    "        os.path.join(BASE_DIR, 'data', 'test_data', '3f_2.csv'),\n",
    "        os.path.join(BASE_DIR, 'data', 'test_data', '3f_swing1.csv'),\n",
    "        os.path.join(BASE_DIR, 'data', 'test_data', '3f_swing2.csv'),\n",
    "        os.path.join(BASE_DIR, 'data', 'test_data', '3f_looking01.csv'),\n",
    "        os.path.join(BASE_DIR, 'data', 'test_data', '3f_looking02.csv')\n",
    "    ]\n",
    "    \n",
    "    # 각 테스트 파일에 대해 예측 수행\n",
    "    for test_path in test_paths:\n",
    "        if os.path.exists(test_path):\n",
    "            print(f\"\\n테스트 파일 처리 중: {os.path.basename(test_path)}\")\n",
    "            \n",
    "            # 테스트 데이터 로드 및 전처리\n",
    "            df_test = DataProcessor.load_and_preprocess_csv(test_path, skiprows=50)\n",
    "            \n",
    "            # 예측 경로 시각화\n",
    "            predictor.predict_and_plot_trajectory(df_test)\n",
    "            \n",
    "            # 그래프 표시\n",
    "            plt.show()\n",
    "            \n",
    "        else:\n",
    "            print(f\"테스트 파일을 찾을 수 없습니다: {test_path}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow Environment",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
